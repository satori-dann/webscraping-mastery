Day 1 â€“ Warm-up
Target: Books to Scrape

Goal: Title, price, rating

Bonus: Get the product page URL

Day 2 â€“ Real News
Target: https://news.ycombinator.com

Goal: Title, score, post link

Bonus: Scrape the second page

Day 3 â€“ Job Listings
Target: https://remoteok.io

Goal: Job title, company, location

Bonus: Extract tags or apply URL

Day 4 â€“ API Discovery
Target: https://quotes.toscrape.com (has an API!)

Goal: Scrape via XHR API, not HTML

Bonus: Paginate through all pages

Day 5 â€“ JavaScript DOM
Target: https://www.realtor.com/ or similar JS-heavy site

Goal: Use selenium or requests-html

Bonus: Screenshot rendered page

Day 6 â€“ Image Scraping
Target: https://unsplash.com or Pexels

Goal: Download 10 image URLs + captions

Bonus: Save actual image files

Day 7 â€“ Product Hunting
Target: Amazon (or webscraper.io/test-sites)

Goal: Product name, price, rating

Bonus: Random user-agent header + retry on fail

Day 8 â€“ Scraping from API
Target: https://pokeapi.co or any open JSON API

Goal: Pull structured data directly

Bonus: Store in SQLite

Day 9 â€“ Real-Time Data
Target: CoinGecko API or scraping CoinMarketCap

Goal: Crypto name, price, 24h change

Bonus: Auto-refresh every 60 seconds (loop)

Day 10 â€“ Custom Dashboard
Goal: Pick your favorite past scrape and:

Format it as a personal dashboard (CSV or HTML)

Automate daily updates

Bonus: Wrap it with Flask and view in browser



ðŸ“‚ Template Repo
web-scraping-80-20/
â”œâ”€â”€ day_01_books/
â”‚   â”œâ”€â”€ scrape.py
â”‚   â””â”€â”€ output.csv
â”œâ”€â”€ day_02_hackernews/
â”‚   â”œâ”€â”€ scrape.py
â”‚   â””â”€â”€ output.csv
â”œâ”€â”€ ...
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ save_csv.py     # optional helper to save data
â”‚   â””â”€â”€ headers.py      # random user agents, etc.
â”œâ”€â”€ README.md           # progress log + instructions
â””â”€â”€ requirements.txt    # libraries used


#lxml was made an requirement, code was added to scrape.py for day_01
